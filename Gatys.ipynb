{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired size of the output image\n",
    "imsize = 512 if torch.cuda.is_available() else 128  # use small size if no gpu\n",
    "\n",
    "loader = transforms.Compose([\n",
    "    transforms.Resize(imsize),  # scale imported image\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    # fake batch dimension required to fit network's input dimensions\n",
    "    image = loader(image).unsqueeze(0)\n",
    "    return image.to(device, torch.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unloader = transforms.ToPILImage()  # reconvert into PIL image\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.cpu().clone()  # we clone the tensor to not do changes on it\n",
    "    image = image.squeeze(0)      # remove the fake batch dimension\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) # pause a bit so that plots are updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, target,):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        # we 'detach' the target content from the tree used\n",
    "        # to dynamically compute the gradient: this is a stated value,\n",
    "        # not a variable. Otherwise the forward method of the criterion\n",
    "        # will throw an error.\n",
    "        self.target = target.detach()\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.loss = F.mse_loss(input, self.target)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input):\n",
    "    a, b, c, d = input.size()  # a=batch size(=1)\n",
    "    # b=number of feature maps\n",
    "    # (c,d)=dimensions of a f. map (N=c*d)\n",
    "\n",
    "    features = input.view(a * b, c * d)  # resise F_XL into \\hat F_XL\n",
    "\n",
    "    G = torch.mm(features, features.t())  # compute the gram product\n",
    "\n",
    "    # we 'normalize' the values of the gram matrix\n",
    "    # by dividing by the number of element in each feature maps.\n",
    "    return G.div(a * b * c * d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class StyleLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, target_feature):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = gram_matrix(target_feature).detach()\n",
    "\n",
    "    def forward(self, input):\n",
    "        G = gram_matrix(input)\n",
    "        self.loss = F.mse_loss(G, self.target)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.vgg19(pretrained=True).features.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "\n",
    "# create a module to normalize input image so we can easily put it in a\n",
    "# nn.Sequential\n",
    "class Normalization(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalization, self).__init__()\n",
    "        # .view the mean and std to make them [C x 1 x 1] so that they can\n",
    "        # directly work with image Tensor of shape [B x C x H x W].\n",
    "        # B is batch size. C is number of channels. H is height and W is width.\n",
    "        self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
    "        self.std = torch.tensor(std).view(-1, 1, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        # normalize img\n",
    "        return (img - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired depth layers to compute style/content losses :\n",
    "content_layers_default = ['conv_4']\n",
    "style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "\n",
    "def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n",
    "                               style_img, content_img,\n",
    "                               content_layers=content_layers_default,\n",
    "                               style_layers=style_layers_default):\n",
    "    cnn = copy.deepcopy(cnn)\n",
    "\n",
    "    # normalization module\n",
    "    normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
    "\n",
    "    # just in order to have an iterable access to or list of content/syle\n",
    "    # losses\n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    "\n",
    "    # assuming that cnn is a nn.Sequential, so we make a new nn.Sequential\n",
    "    # to put in modules that are supposed to be activated sequentially\n",
    "    model = nn.Sequential(normalization)\n",
    "\n",
    "    i = 0  # increment every time we see a conv\n",
    "    for layer in cnn.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            i += 1\n",
    "            name = 'conv_{}'.format(i)\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            name = 'relu_{}'.format(i)\n",
    "            # The in-place version doesn't play very nicely with the ContentLoss\n",
    "            # and StyleLoss we insert below. So we replace with out-of-place\n",
    "            # ones here.\n",
    "            layer = nn.ReLU(inplace=False)\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            name = 'pool_{}'.format(i)\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            name = 'bn_{}'.format(i)\n",
    "        else:\n",
    "            raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
    "\n",
    "        model.add_module(name, layer)\n",
    "\n",
    "        if name in content_layers:\n",
    "            # add content loss:\n",
    "            target = model(content_img).detach()\n",
    "            content_loss = ContentLoss(target)\n",
    "            model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
    "            content_losses.append(content_loss)\n",
    "\n",
    "        if name in style_layers:\n",
    "            # add style loss:\n",
    "            target_feature = model(style_img).detach()\n",
    "            style_loss = StyleLoss(target_feature)\n",
    "            model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "\n",
    "    # now we trim off the layers after the last content and style losses\n",
    "    for i in range(len(model) - 1, -1, -1):\n",
    "        if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
    "            break\n",
    "\n",
    "    model = model[:(i + 1)]\n",
    "\n",
    "    return model, style_losses, content_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_optimizer(input_img):\n",
    "    # this line to show that input is a parameter that requires a gradient\n",
    "    optimizer = optim.LBFGS([input_img.requires_grad_()])\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "def run_style_transfer(cnn, normalization_mean, normalization_std,\n",
    "                       content_img, style_img, input_img, num_steps=300,\n",
    "                       style_weight=1000000, content_weight=1):\n",
    "    \"\"\"Run the style transfer.\"\"\"\n",
    "    print('Building the style transfer model..')\n",
    "    model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
    "        normalization_mean, normalization_std, style_img, content_img)\n",
    "    optimizer = get_input_optimizer(input_img)\n",
    "\n",
    "    print('Optimizing..')\n",
    "    run = [0]\n",
    "    while run[0] <= num_steps:\n",
    "\n",
    "        def closure():\n",
    "            # correct the values of updated input image\n",
    "            input_img.data.clamp_(0, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model(input_img)\n",
    "            style_score = 0\n",
    "            content_score = 0\n",
    "\n",
    "            for sl in style_losses:\n",
    "                style_score += sl.loss\n",
    "            for cl in content_losses:\n",
    "                content_score += cl.loss\n",
    "\n",
    "            style_score *= style_weight\n",
    "            content_score *= content_weight\n",
    "\n",
    "            loss = style_score + content_score\n",
    "            loss.backward()\n",
    "\n",
    "            run[0] += 1\n",
    "            if run[0] % 50 == 0:\n",
    "                print(\"run {}:\".format(run))\n",
    "                print('Style Loss : {:4f} Content Loss: {:4f}'.format(\n",
    "                    style_score.item(), content_score.item()))\n",
    "                print()\n",
    "\n",
    "            return style_score + content_score\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    # a last correction...\n",
    "    input_img.data.clamp_(0, 1)\n",
    "\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.919244 Content Loss: 3.417791\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 10.934398 Content Loss: 5.482408\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 2.939625 Content Loss: 3.989671\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 1.879240 Content Loss: 3.417105\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.456349 Content Loss: 3.107071\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.147094 Content Loss: 2.932899\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.895871 Content Loss: 2.838857\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 12.446113 Content Loss: 6.511493\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.008475 Content Loss: 4.982727\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 1.897423 Content Loss: 4.301957\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.515947 Content Loss: 3.957761\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.232024 Content Loss: 3.774171\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.992796 Content Loss: 3.669293\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 16.000792 Content Loss: 6.965091\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.735947 Content Loss: 5.215741\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.292127 Content Loss: 4.486346\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.780280 Content Loss: 4.123094\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.414920 Content Loss: 3.938284\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.102316 Content Loss: 3.837398\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 11.664927 Content Loss: 7.021125\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.238962 Content Loss: 5.242902\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 1.905541 Content Loss: 4.556513\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.531044 Content Loss: 4.189263\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.281445 Content Loss: 3.987402\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.053980 Content Loss: 3.875932\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 13.865315 Content Loss: 7.034094\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.206014 Content Loss: 5.246649\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 1.985219 Content Loss: 4.514858\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.574620 Content Loss: 4.127794\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.275475 Content Loss: 3.930352\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.020475 Content Loss: 3.817719\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 13.485838 Content Loss: 6.211514\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.594050 Content Loss: 4.552490\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.084679 Content Loss: 4.076724\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.493391 Content Loss: 3.838484\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.135114 Content Loss: 3.706328\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.887136 Content Loss: 3.644909\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 14.773602 Content Loss: 6.348716\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.889744 Content Loss: 4.675902\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.172432 Content Loss: 4.194698\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.520316 Content Loss: 3.909908\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.182945 Content Loss: 3.769576\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.930179 Content Loss: 3.709893\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 11.781359 Content Loss: 6.227738\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.306662 Content Loss: 4.585882\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 1.924172 Content Loss: 4.116156\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.411292 Content Loss: 3.832959\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.109502 Content Loss: 3.702910\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.879205 Content Loss: 3.644892\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 13.616215 Content Loss: 6.889630\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.584836 Content Loss: 5.249198\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.158815 Content Loss: 4.505681\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.694934 Content Loss: 4.123722\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.360121 Content Loss: 3.930941\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.066806 Content Loss: 3.828271\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 15.502829 Content Loss: 7.113093\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.323321 Content Loss: 5.441063\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.516062 Content Loss: 4.710229\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.908846 Content Loss: 4.291281\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.520781 Content Loss: 4.082148\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.183768 Content Loss: 3.975533\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 14.590938 Content Loss: 5.359603\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.022941 Content Loss: 4.031142\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.438893 Content Loss: 3.317468\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.713091 Content Loss: 2.963610\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.323789 Content Loss: 2.771337\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.034123 Content Loss: 2.652448\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 17.654490 Content Loss: 6.352608\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.312262 Content Loss: 4.744219\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.429527 Content Loss: 4.112034\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.620278 Content Loss: 3.825663\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.242344 Content Loss: 3.659955\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.988104 Content Loss: 3.567274\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 14.930244 Content Loss: 6.796626\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.906355 Content Loss: 5.262369\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.357204 Content Loss: 4.441631\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.707213 Content Loss: 4.049185\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.329534 Content Loss: 3.843788\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.062478 Content Loss: 3.722162\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 16.475346 Content Loss: 6.980469\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.520115 Content Loss: 5.707441\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.501000 Content Loss: 4.952511\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.832314 Content Loss: 4.553302\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.479253 Content Loss: 4.325245\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.216599 Content Loss: 4.198112\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 16.656227 Content Loss: 6.995669\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.117050 Content Loss: 5.607115\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.430227 Content Loss: 4.956281\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.795473 Content Loss: 4.560326\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.461654 Content Loss: 4.335102\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.210072 Content Loss: 4.209542\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 15.149880 Content Loss: 5.892623\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.989815 Content Loss: 4.756424\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.243867 Content Loss: 3.963079\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.625988 Content Loss: 3.564304\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.306380 Content Loss: 3.343060\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.062376 Content Loss: 3.225756\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 14.184909 Content Loss: 6.526803\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.208727 Content Loss: 5.105506\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.340896 Content Loss: 4.619406\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.646496 Content Loss: 4.324987\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.330239 Content Loss: 4.132197\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.107180 Content Loss: 4.035570\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 18.187817 Content Loss: 6.855890\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.833557 Content Loss: 5.560559\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.860130 Content Loss: 4.889288\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.986438 Content Loss: 4.552884\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.546407 Content Loss: 4.342077\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.240099 Content Loss: 4.219334\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 20.424023 Content Loss: 6.641629\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 6.408558 Content Loss: 5.566437\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 3.263260 Content Loss: 4.900379\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 2.198689 Content Loss: 4.519070\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.656079 Content Loss: 4.294480\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.314856 Content Loss: 4.158092\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 21.532368 Content Loss: 6.582936\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 5.597044 Content Loss: 5.247134\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.985885 Content Loss: 4.478555\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 2.031048 Content Loss: 4.091061\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.504997 Content Loss: 3.894622\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.178751 Content Loss: 3.766625\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 21.218330 Content Loss: 6.863491\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 6.147946 Content Loss: 5.624386\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 3.650064 Content Loss: 5.021876\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 2.510552 Content Loss: 4.692107\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.846178 Content Loss: 4.479590\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.423884 Content Loss: 4.355132\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 19.454163 Content Loss: 6.825083\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.530141 Content Loss: 5.452806\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.739909 Content Loss: 4.808352\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.848515 Content Loss: 4.490165\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.410781 Content Loss: 4.315605\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.125995 Content Loss: 4.218523\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 16.645130 Content Loss: 6.488177\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.535115 Content Loss: 5.005768\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.086957 Content Loss: 4.312358\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.451831 Content Loss: 3.953575\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.170967 Content Loss: 3.758818\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.988930 Content Loss: 3.651428\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 16.240255 Content Loss: 5.523215\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.381941 Content Loss: 4.194658\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.514184 Content Loss: 3.557170\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.694989 Content Loss: 3.240940\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.260698 Content Loss: 3.067062\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.947403 Content Loss: 2.967556\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 14.422672 Content Loss: 5.413002\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.926217 Content Loss: 4.068744\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.227953 Content Loss: 3.446675\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.560860 Content Loss: 3.164075\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.195772 Content Loss: 3.011651\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.914469 Content Loss: 2.930155\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 15.107909 Content Loss: 6.562057\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.564506 Content Loss: 4.985329\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.085003 Content Loss: 4.347370\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.562125 Content Loss: 4.034649\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.232939 Content Loss: 3.872874\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.976101 Content Loss: 3.779458\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 14.970999 Content Loss: 6.923602\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.354418 Content Loss: 5.333433\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 1.969119 Content Loss: 4.658648\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.458719 Content Loss: 4.281812\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.171462 Content Loss: 4.084126\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.945681 Content Loss: 3.970191\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 13.479225 Content Loss: 6.833892\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.443210 Content Loss: 5.150304\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.008067 Content Loss: 4.500643\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.501067 Content Loss: 4.183378\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.217502 Content Loss: 4.020518\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.977796 Content Loss: 3.935460\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 16.287327 Content Loss: 6.896266\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.936059 Content Loss: 5.321432\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.188793 Content Loss: 4.602479\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.591138 Content Loss: 4.257300\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.275238 Content Loss: 4.083860\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.024857 Content Loss: 3.989013\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 14.720271 Content Loss: 6.873542\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.812182 Content Loss: 5.162998\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.170346 Content Loss: 4.497912\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.565619 Content Loss: 4.162234\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.227121 Content Loss: 3.987322\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.971096 Content Loss: 3.890165\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 13.010109 Content Loss: 6.720282\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.700140 Content Loss: 5.054681\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 1.845215 Content Loss: 4.390854\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.370630 Content Loss: 4.027588\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.113306 Content Loss: 3.843394\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.907740 Content Loss: 3.739272\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 15.316463 Content Loss: 6.286493\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.212048 Content Loss: 4.922827\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.331345 Content Loss: 4.161928\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.547636 Content Loss: 3.818183\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.211460 Content Loss: 3.619068\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.995047 Content Loss: 3.511988\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 13.686501 Content Loss: 6.707670\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.370405 Content Loss: 5.105988\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.051287 Content Loss: 4.329876\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.470180 Content Loss: 3.958726\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.176319 Content Loss: 3.758372\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.981224 Content Loss: 3.644857\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 12.939178 Content Loss: 6.488415\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.847233 Content Loss: 5.015528\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.051916 Content Loss: 4.475192\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.444721 Content Loss: 4.158711\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.180164 Content Loss: 3.974513\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.996329 Content Loss: 3.882130\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 13.767201 Content Loss: 6.087658\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.656739 Content Loss: 4.756345\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.521317 Content Loss: 4.042449\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.761151 Content Loss: 3.671824\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.350772 Content Loss: 3.469236\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.063958 Content Loss: 3.362037\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 13.197906 Content Loss: 6.067791\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.953493 Content Loss: 4.723524\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 1.985072 Content Loss: 3.964853\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.449699 Content Loss: 3.570678\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.177948 Content Loss: 3.349971\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.972782 Content Loss: 3.233512\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 15.488265 Content Loss: 5.553281\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.353890 Content Loss: 4.153522\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 1.923430 Content Loss: 3.380146\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.353460 Content Loss: 2.987674\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.038538 Content Loss: 2.773504\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.847561 Content Loss: 2.648951\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 10.327773 Content Loss: 6.374874\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 3.294647 Content Loss: 4.934447\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 1.721727 Content Loss: 4.376745\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.253011 Content Loss: 4.087891\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.053861 Content Loss: 3.919702\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.923246 Content Loss: 3.841820\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 15.045439 Content Loss: 6.628420\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.216265 Content Loss: 5.187997\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.270950 Content Loss: 4.605747\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.571673 Content Loss: 4.263969\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.245277 Content Loss: 4.034903\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.045293 Content Loss: 3.904698\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 16.442135 Content Loss: 6.591135\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.950118 Content Loss: 5.114612\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.788076 Content Loss: 4.369354\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.808017 Content Loss: 4.037606\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.361368 Content Loss: 3.827807\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.081084 Content Loss: 3.702981\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 16.073969 Content Loss: 6.630417\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 5.080369 Content Loss: 5.401777\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.679979 Content Loss: 4.773282\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.793137 Content Loss: 4.424866\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.405574 Content Loss: 4.201291\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.145356 Content Loss: 4.069675\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 18.564575 Content Loss: 6.525888\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 6.426343 Content Loss: 4.941794\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 3.768319 Content Loss: 4.372565\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 2.280121 Content Loss: 4.123295\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.626358 Content Loss: 3.949926\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.217090 Content Loss: 3.842416\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 14.399600 Content Loss: 6.461478\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.817363 Content Loss: 5.113492\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.415886 Content Loss: 4.608199\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.648543 Content Loss: 4.303854\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.326350 Content Loss: 4.107824\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.093210 Content Loss: 4.017842\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 13.737830 Content Loss: 6.485064\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 5.387774 Content Loss: 5.100729\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.632249 Content Loss: 4.641176\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.765258 Content Loss: 4.358297\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.392490 Content Loss: 4.157063\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.129408 Content Loss: 4.065706\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 16.946867 Content Loss: 6.381924\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 5.134161 Content Loss: 4.915168\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.785753 Content Loss: 4.323345\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.763399 Content Loss: 4.059722\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.328326 Content Loss: 3.870470\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 1.053372 Content Loss: 3.767583\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 15.841779 Content Loss: 4.309260\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.725665 Content Loss: 3.507549\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.341632 Content Loss: 2.945001\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.508900 Content Loss: 2.647490\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.158790 Content Loss: 2.436756\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.950844 Content Loss: 2.320508\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 15.383371 Content Loss: 4.099220\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.708078 Content Loss: 3.102977\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.381740 Content Loss: 2.541021\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.511406 Content Loss: 2.294065\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.141676 Content Loss: 2.118140\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.917498 Content Loss: 2.022767\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 14.098628 Content Loss: 4.243220\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.444806 Content Loss: 3.232000\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.479799 Content Loss: 2.635015\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.632284 Content Loss: 2.396856\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.227399 Content Loss: 2.232151\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.974426 Content Loss: 2.122286\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 13.881333 Content Loss: 4.200773\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.124317 Content Loss: 3.126673\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.079981 Content Loss: 2.553126\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.285234 Content Loss: 2.289660\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.014646 Content Loss: 2.108909\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.831825 Content Loss: 2.012823\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 16.376472 Content Loss: 4.371082\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.763855 Content Loss: 3.261438\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.543252 Content Loss: 2.681069\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.550574 Content Loss: 2.397714\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.185048 Content Loss: 2.216812\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.951869 Content Loss: 2.115901\n",
      "\n",
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [50]:\n",
      "Style Loss : 12.212779 Content Loss: 4.065521\n",
      "\n",
      "run [100]:\n",
      "Style Loss : 4.000977 Content Loss: 2.772301\n",
      "\n",
      "run [150]:\n",
      "Style Loss : 2.153317 Content Loss: 2.337155\n",
      "\n",
      "run [200]:\n",
      "Style Loss : 1.411232 Content Loss: 2.092788\n",
      "\n",
      "run [250]:\n",
      "Style Loss : 1.063531 Content Loss: 1.961849\n",
      "\n",
      "run [300]:\n",
      "Style Loss : 0.805286 Content Loss: 1.906896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(150):\n",
    "    style_img = image_loader(f\"captures_new_porcine/DS_0001_frame_{i}.jpg\")\n",
    "    content_img = image_loader(f\"captures_new_vr/DS_0001_frame_{i}.jpg\")\n",
    "    input_img = content_img.clone()\n",
    "    output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,content_img, style_img, input_img)\n",
    "    torchvision.utils.save_image(output, f'Gatys_output/sample{i}.jpg', nrow=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}